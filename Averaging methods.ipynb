{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Unequal Data Distribution Scenario:\n",
      "Accuracy with Simple Averaging: 64.45%\n",
      "Accuracy with Weighted Averaging: 93.99%\n",
      "Simple Averaging Accuracy: 64.45%\n",
      "Weighted Averaging Accuracy: 93.99%\n",
      "Results for Unequal Data Distribution Scenario:\n",
      "Accuracy with Simple Averaging: 38.84%\n",
      "Accuracy with Weighted Averaging: 60.51%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "def prepare_data_loaders():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.random.permutation(dataset_size)\n",
    "\n",
    "    # Calculate splits\n",
    "    split20 = int(np.floor(0.2 * dataset_size))\n",
    "    split40 = int(np.floor(0.4 * dataset_size))\n",
    "\n",
    "    # Assign 20% to three clients and 40% to one client\n",
    "    loader1 = DataLoader(Subset(dataset, indices[:split20]), batch_size=64, shuffle=True)\n",
    "    loader2 = DataLoader(Subset(dataset, indices[split20:2*split20]), batch_size=64, shuffle=True)\n",
    "    loader3 = DataLoader(Subset(dataset, indices[2*split20:3*split20]), batch_size=64, shuffle=True)\n",
    "    loader4 = DataLoader(Subset(dataset, indices[3*split20:3*split20 + split40]), batch_size=64, shuffle=True)\n",
    "\n",
    "    return loader1, loader2, loader3, loader4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training function for a model\n",
    "def train_model(model, data_loader, device, epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Aggregation functions\n",
    "def average_models(models, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] for model in models], 0).mean(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def weighted_average_models(models, weights, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] * weight for model, weight in zip(models, weights)], 0).sum(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def run_experiment():\n",
    "    loader1, loader2, loader3, loader4 = prepare_data_loaders()\n",
    "    test_loader = DataLoader(datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])), batch_size=64, shuffle=False)\n",
    "\n",
    "    models = [SimpleCNN().to(device) for _ in range(4)]\n",
    "    for i, model in enumerate(models):\n",
    "        train_model(model, [loader1, loader2, loader3, loader4][i], device)\n",
    "\n",
    "    # Weights reflecting the percentage of data each client has\n",
    "    weights = [0.2, 0.2, 0.2, 0.4]  # 20% for three clients, 40% for one client\n",
    "\n",
    "    simple_avg_model = average_models(models, device)\n",
    "    weighted_avg_model = weighted_average_models(models, weights, device)\n",
    "\n",
    "    simple_avg_accuracy = evaluate_model(simple_avg_model, test_loader, device)\n",
    "    weighted_avg_accuracy = evaluate_model(weighted_avg_model, test_loader, device)\n",
    "\n",
    "    print(f\"Results for Unequal Data Distribution Scenario:\")\n",
    "    print(f\"Accuracy with Simple Averaging: {simple_avg_accuracy:.2f}%\")\n",
    "    print(f\"Accuracy with Weighted Averaging: {weighted_avg_accuracy:.2f}%\")\n",
    "\n",
    "    return simple_avg_accuracy, weighted_avg_accuracy\n",
    "\n",
    "# Execute the experiment\n",
    "iid_simple_acc, iid_weighted_acc = run_experiment()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Simple Averaging Accuracy: {iid_simple_acc:.2f}%\")\n",
    "print(f\"Weighted Averaging Accuracy: {iid_weighted_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Run experiment\n",
    "iid_simple_acc, iid_weighted_acc = run_experiment()\n",
    "\n",
    "# Plotting the results\n",
    "labels = ['Simple Averaging', 'Weighted Averaging']\n",
    "accuracies = [iid_simple_acc, iid_weighted_acc]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(labels, accuracies, color=['blue', 'green'])\n",
    "plt.xlabel('Averaging Method')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Comparison of Averaging Methods in Mixed IID and Non-IID Scenarios (MNIST)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Results for CIFAR-10 with Unequal Data Distribution Scenario:\n",
      "Accuracy with Simple Averaging: 14.27%\n",
      "Accuracy with Weighted Averaging: 22.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture for CIFAR-10\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Adjusted for the downsampled image size\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def prepare_data_loaders():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Appropriate for RGB\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.random.permutation(dataset_size)\n",
    "\n",
    "    split20 = int(np.floor(0.2 * dataset_size))\n",
    "    split40 = int(np.floor(0.4 * dataset_size))\n",
    "\n",
    "    loader1 = DataLoader(Subset(dataset, indices[:split20]), batch_size=64, shuffle=True)\n",
    "    loader2 = DataLoader(Subset(dataset, indices[split20:2*split20]), batch_size=64, shuffle=True)\n",
    "    loader3 = DataLoader(Subset(dataset, indices[2*split20:3*split20]), batch_size=64, shuffle=True)\n",
    "    loader4 = DataLoader(Subset(dataset, indices[3*split20:3*split20 + split40]), batch_size=64, shuffle=True)\n",
    "\n",
    "    return loader1, loader2, loader3, loader4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, data_loader, device, epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def average_models(models, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] for model in models], 0).mean(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def weighted_average_models(models, weights, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] * weight for model, weight in zip(models, weights)], 0).sum(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def run_experiment():\n",
    "    loader1, loader2, loader3, loader4 = prepare_data_loaders()\n",
    "    test_loader = DataLoader(datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])), batch_size=64, shuffle=False)\n",
    "\n",
    "    models = [SimpleCNN().to(device) for _ in range(4)]\n",
    "    for i, model in enumerate(models):\n",
    "        train_model(model, [loader1, loader2, loader3, loader4][i], device)\n",
    "\n",
    "    weights = [0.2, 0.2, 0.2, 0.4]  # Reflecting the data distribution\n",
    "\n",
    "    simple_avg_model = average_models(models, device)\n",
    "    weighted_avg_model = weighted_average_models(models, weights, device)\n",
    "\n",
    "    simple_avg_accuracy = evaluate_model(simple_avg_model, test_loader, device)\n",
    "    weighted_avg_accuracy = evaluate_model(weighted_avg_model, test_loader, device)\n",
    "\n",
    "    print(f\"Results for CIFAR-10 with Unequal Data Distribution Scenario:\")\n",
    "    print(f\"Accuracy with Simple Averaging: {simple_avg_accuracy:.2f}%\")\n",
    "    print(f\"Accuracy with Weighted Averaging: {weighted_avg_accuracy:.2f}%\")\n",
    "\n",
    "    return simple_avg_accuracy, weighted_avg_accuracy\n",
    "\n",
    "iid_simple_acc, iid_weighted_acc = run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Equal Data Distribution Scenario:\n",
      "Accuracy with Simple Averaging: 70.90%\n",
      "Accuracy with Weighted Averaging: 70.90%\n",
      "Simple Averaging Accuracy: 70.90%\n",
      "Weighted Averaging Accuracy: 70.90%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture suitable for MNIST\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Adjusted for 1-channel grayscale images\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)  # Adjusted for the downsampled image size\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def prepare_data_loaders():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Appropriate for grayscale images\n",
    "    ])\n",
    "    dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.random.permutation(dataset_size)\n",
    "\n",
    "    # Evenly distribute data: 25% to each client\n",
    "    split = int(dataset_size / 4)\n",
    "\n",
    "    loader1 = DataLoader(Subset(dataset, indices[:split]), batch_size=64, shuffle=True)\n",
    "    loader2 = DataLoader(Subset(dataset, indices[split:2*split]), batch_size=64, shuffle=True)\n",
    "    loader3 = DataLoader(Subset(dataset, indices[2*split:3*split]), batch_size=64, shuffle=True)\n",
    "    loader4 = DataLoader(Subset(dataset, indices[3*split:]), batch_size=64, shuffle=True)\n",
    "\n",
    "    return loader1, loader2, loader3, loader4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, data_loader, device, epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def average_models(models, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] for model in models], 0).mean(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def weighted_average_models(models, weights, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] * weight for model, weight in zip(models, weights)], 0).sum(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def run_experiment():\n",
    "    loader1, loader2, loader3, loader4 = prepare_data_loaders()\n",
    "    test_loader = DataLoader(datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])), batch_size=64, shuffle=False)\n",
    "\n",
    "    models = [SimpleCNN().to(device) for _ in range(4)]\n",
    "    for i, model in enumerate(models):\n",
    "        train_model(model, [loader1, loader2, loader3, loader4][i], device)\n",
    "\n",
    "    weights = [0.25, 0.25, 0.25, 0.25]  # Equal weights reflecting equal data distribution\n",
    "\n",
    "    simple_avg_model = average_models(models, device)\n",
    "    weighted_avg_model = weighted_average_models(models, weights, device)\n",
    "\n",
    "    simple_avg_accuracy = evaluate_model(simple_avg_model, test_loader, device)\n",
    "    weighted_avg_accuracy = evaluate_model(weighted_avg_model, test_loader, device)\n",
    "\n",
    "    print(f\"Results for Equal Data Distribution Scenario:\")\n",
    "    print(f\"Accuracy with Simple Averaging: {simple_avg_accuracy:.2f}%\")\n",
    "    print(f\"Accuracy with Weighted Averaging: {weighted_avg_accuracy:.2f}%\")\n",
    "\n",
    "    return simple_avg_accuracy, weighted_avg_accuracy\n",
    "\n",
    "iid_simple_acc, iid_weighted_acc = run_experiment()\n",
    "\n",
    "print(f\"Simple Averaging Accuracy: {iid_simple_acc:.2f}%\")\n",
    "print(f\"Weighted Averaging Accuracy: {iid_weighted_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Results for CIFAR-10 with Equal Data Distribution Scenario:\n",
      "Accuracy with Simple Averaging: 17.22%\n",
      "Accuracy with Weighted Averaging: 17.22%\n",
      "Simple Averaging Accuracy: 17.22%\n",
      "Weighted Averaging Accuracy: 17.22%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture for CIFAR-10\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # For 3-channel RGB images\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Adjusted for CIFAR-10's 32x32 images after pooling\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def prepare_data_loaders():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization for CIFAR-10\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.random.permutation(dataset_size)\n",
    "\n",
    "    # Evenly distribute data: 25% to each client\n",
    "    split = int(dataset_size / 4)\n",
    "\n",
    "    loader1 = DataLoader(Subset(dataset, indices[:split]), batch_size=64, shuffle=True)\n",
    "    loader2 = DataLoader(Subset(dataset, indices[split:2*split]), batch_size=64, shuffle=True)\n",
    "    loader3 = DataLoader(Subset(dataset, indices[2*split:3*split]), batch_size=64, shuffle=True)\n",
    "    loader4 = DataLoader(Subset(dataset, indices[3*split:]), batch_size=64, shuffle=True)\n",
    "\n",
    "    return loader1, loader2, loader3, loader4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, data_loader, device, epochs=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def average_models(models, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] for model in models], 0).mean(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def weighted_average_models(models, weights, device):\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.stack([model.state_dict()[key] * weight for model, weight in zip(models, weights)], 0).sum(0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    return global_model\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def run_experiment():\n",
    "    loader1, loader2, loader3, loader4 = prepare_data_loaders()\n",
    "    test_loader = DataLoader(datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])), batch_size=64, shuffle=False)\n",
    "\n",
    "    models = [SimpleCNN().to(device) for _ in range(4)]\n",
    "    for i, model in enumerate(models):\n",
    "        train_model(model, [loader1, loader2, loader3, loader4][i], device)\n",
    "\n",
    "    weights = [0.25, 0.25, 0.25, 0.25]  # Equal weights reflecting equal data distribution\n",
    "\n",
    "    simple_avg_model = average_models(models, device)\n",
    "    weighted_avg_model = weighted_average_models(models, weights, device)\n",
    "\n",
    "    simple_avg_accuracy = evaluate_model(simple_avg_model, test_loader, device)\n",
    "    weighted_avg_accuracy = evaluate_model(weighted_avg_model, test_loader, device)\n",
    "\n",
    "    print(f\"Results for CIFAR-10 with Equal Data Distribution Scenario:\")\n",
    "    print(f\"Accuracy with Simple Averaging: {simple_avg_accuracy:.2f}%\")\n",
    "    print(f\"Accuracy with Weighted Averaging: {weighted_avg_accuracy:.2f}%\")\n",
    "\n",
    "    return simple_avg_accuracy, weighted_avg_accuracy\n",
    "\n",
    "iid_simple_acc, iid_weighted_acc = run_experiment()\n",
    "\n",
    "print(f\"Simple Averaging Accuracy: {iid_simple_acc:.2f}%\")\n",
    "print(f\"Weighted Averaging Accuracy: {iid_weighted_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
